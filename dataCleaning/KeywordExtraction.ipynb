{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction using News Articles\n",
    "\n",
    "#newsapi #KeywordExtraction #ElectricVehicles #CO2Emissions\n",
    "\n",
    "The goal of this document is to extract keywords \n",
    "that are associated with the environmental downsides \n",
    "of an electric vehicle that are covered in mainstream\n",
    "media sources. The API used here is for newsapi.org.\n",
    "\n",
    "This jupyter notebook includes:\n",
    "- Data gathering from newsapi.org\n",
    "- Data cleaning and feature extraction on the newsapi.org dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, use API to gather news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "my_api_key = \"fea5c56a315742a8bcc16a4c19a1b31e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key = my_api_key)\n",
    "data = newsapi.get_everything(q = \"(electric vehicles OR EV OR EVs) AND (carbon footprint OR CO2 Emissions)\", language = 'en', page_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['status', 'totalResults', 'articles'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The structure of the pulled dataset is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _data_ object is a dictionary with keys {'status', 'totalResults', 'articles'}, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> dict_keys(['status', 'totalResults', 'articles'])\n"
     ]
    }
   ],
   "source": [
    "print(type(data), data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, it can be checked using the 'status' key that my search went as wished, and the number of relevant search results is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 1874\n"
     ]
    }
   ],
   "source": [
    "print(data['status'] == 'ok', data['totalResults'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since my account isn't a developer account, this dataset is going to contain just 100 news articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(data['articles']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for all these datasets, it will be helpful to gather the text data into a data frame \n",
    "to prep for some data cleaning and later on, clustering. As can be seen below, the articles\n",
    "are stored in a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'dict'> 100\n"
     ]
    }
   ],
   "source": [
    "print(type(data['articles']), type(data['articles'][0]), len(data['articles']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some good information about the storage structure for each article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': {'id': 'techcrunch', 'name': 'TechCrunch'}, 'author': 'Walter Thompson', 'title': 'EV charging solutions will become an asset, not a liability, to the grid', 'description': 'Although wireless charging is still relatively new to the market, the benefits are beginning to become glaringly self-evident.', 'url': 'http://techcrunch.com/2021/08/31/ev-charging-solutions-will-become-an-asset-not-a-liability-to-the-grid/', 'urlToImage': 'https://techcrunch.com/wp-content/uploads/2021/08/GettyImages-1219328171.jpg?w=600', 'publishedAt': '2021-08-31T14:30:08Z', 'content': 'President Joe Biden’s plan for electric vehicles (EVs) to comprise roughly half of U.S. sales by 2030 is a clear indication that the U.S. is making strides in decarbonizing its transportation systems… [+8883 chars]'}\n",
      "dict_keys(['source', 'author', 'title', 'description', 'url', 'urlToImage', 'publishedAt', 'content'])\n"
     ]
    }
   ],
   "source": [
    "print(data['articles'][0])\n",
    "print(data['articles'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen above that each article has attributes:\n",
    "{'source', 'author', 'title', 'description', 'url', \n",
    "'urlToImage', 'publishedAt', 'content'}\n",
    "\n",
    "- These variables will be relevant and kept: source, title, publishedAt, content\n",
    "- _source_ could reveal media bias\n",
    "- _title_ is important content\n",
    "- _publishedAt_ is important because EV production technologies are evolving fast, an article from too long ago is not applicable for today\n",
    "- _content_ must be kept for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is Data Cleaning and Feature Extraction\n",
    "\n",
    "1. The articles will be put into a dataframe\n",
    "2. The contents will be converted to bags-of-words (BOW) for further text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _pandas_ library has an amazing function already implemented to convert a dictionary into a data frame. The fucntion is called:\n",
    "\n",
    "> pandas.DataFrame.from_dict()\n",
    "\n",
    "The data can be a list of dictionaries, just like our case. See the documentation [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html#pandas.DataFrame.from_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = data['articles']\n",
    "DF = pd.DataFrame.from_dict(raw_dataset)\n",
    "DF.to_csv('rawNewsData.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      "source         100 non-null object\n",
      "author         72 non-null object\n",
      "title          100 non-null object\n",
      "description    100 non-null object\n",
      "url            100 non-null object\n",
      "urlToImage     100 non-null object\n",
      "publishedAt    100 non-null object\n",
      "content        100 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "Index(['source', 'author', 'title', 'description', 'url', 'urlToImage',\n",
      "       'publishedAt', 'content'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(DF.info())\n",
    "print(DF.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First tasks on this data frame:\n",
    "1. _author, description, url, urlToImage_ are all irrelevant features, so they will be deleted. The relevant DF method is:\n",
    "    > pandas.DataFrame.drop()\n",
    "2. For _source_, only 'name' will be kept\n",
    "3. Each feature has datatype 'object' which needs correction.\n",
    "    - source -- string\n",
    "    - title -- string\n",
    "    - description -- string\n",
    "    - publishedAt -- int, only year\n",
    "    - content -- string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1\n",
    "# documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html\n",
    "drop_labels = ['author', 'url', 'urlToImage']\n",
    "DF = DF.drop(labels = drop_labels, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       TechCrunch\n",
      "1       TechCrunch\n",
      "2        Wiley.com\n",
      "3          Reuters\n",
      "4          Reuters\n",
      "          ...     \n",
      "95    The Guardian\n",
      "96       Zacks.com\n",
      "97         Reuters\n",
      "98         Reuters\n",
      "99         Reuters\n",
      "Name: source, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Task 2\n",
    "for i in range(0,100):\n",
    "    DF['source'][i] = DF['source'][i]['name']\n",
    "print(DF['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TechCrunch\n",
      "<class 'str'>\n",
      "EV charging solutions will become an asset, not a liability, to the grid\n",
      "<class 'str'>\n",
      "Although wireless charging is still relatively new to the market, the benefits are beginning to become glaringly self-evident.\n",
      "<class 'str'>\n",
      "2021-08-31T14:30:08Z\n",
      "<class 'str'>\n",
      "President Joe Biden’s plan for electric vehicles (EVs) to comprise roughly half of U.S. sales by 2030 is a clear indication that the U.S. is making strides in decarbonizing its transportation systems… [+8883 chars]\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "## Task 3\n",
    "for label in DF.columns:\n",
    "    print(DF[label][0])\n",
    "    print(type(DF[label][0]))\n",
    "    \n",
    "# so only publishedAt needs correction, this will be made into int year\n",
    "for i in range(0,100):\n",
    "    DF['publishedAt'][i] = int(DF['publishedAt'][i][0:4]) # Python strings can be sliced like arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>EV charging solutions will become an asset, no...</td>\n",
       "      <td>Although wireless charging is still relatively...</td>\n",
       "      <td>President Joe Biden’s plan for electric vehicl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>Hyundai Motor Group unveils its hydrogen strat...</td>\n",
       "      <td>Hyundai Motor Group is backing hydrogen as a t...</td>\n",
       "      <td>Hyundai Motor Group is backing hydrogen as a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wiley.com</td>\n",
       "      <td>Electric Vehicles produce substantial toxicity...</td>\n",
       "      <td>Electric vehicles (EVs) coupled with low-carbo...</td>\n",
       "      <td>Introduction\\r\\nOur global society is dependen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Zurich Insurance sets climate steps to curb C0...</td>\n",
       "      <td>Zurich Insurance Group &lt;a href=\"https://www.re...</td>\n",
       "      <td>CEO Mario Greco of Swiss Zurich Insurance addr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>UPDATE 1-Zurich Insurance sets climate steps t...</td>\n",
       "      <td>Zurich Insurance Group unveiled new climate me...</td>\n",
       "      <td>By Reuters Staff\\r\\nFILE PHOTO: CEO Mario Grec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Is deep-sea mining a cure for the climate cris...</td>\n",
       "      <td>Trillions of metallic nodules on the sea floor...</td>\n",
       "      <td>In a display cabinet in the recently opened Ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zacks.com</td>\n",
       "      <td>Auto Stock Roundup: AAP &amp; XPEV's Q2 Results, F...</td>\n",
       "      <td>While Advance Auto Parts (AAP) and XPeng (XPEV...</td>\n",
       "      <td>August\\r\\n30, 2021\\r\\n5 min read\\r\\nThis story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Illinois Senate passes bill to save nuclear pl...</td>\n",
       "      <td>The Illinois Senate passed a bill early on Wed...</td>\n",
       "      <td>The company and law firm names shown above are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>Illinois Senate passes bill to save nuclear pl...</td>\n",
       "      <td>The Illinois Senate passed a bill early on Wed...</td>\n",
       "      <td>(Reuters) - The Illinois Senate passed a bill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>UPDATE 1-Illinois Senate passes bill to save n...</td>\n",
       "      <td>The Illinois Senate passed a bill early on Wed...</td>\n",
       "      <td>(Adds Exelon comment)\\r\\nSept 1 (Reuters) - Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source                                              title  \\\n",
       "0     TechCrunch  EV charging solutions will become an asset, no...   \n",
       "1     TechCrunch  Hyundai Motor Group unveils its hydrogen strat...   \n",
       "2      Wiley.com  Electric Vehicles produce substantial toxicity...   \n",
       "3        Reuters  Zurich Insurance sets climate steps to curb C0...   \n",
       "4        Reuters  UPDATE 1-Zurich Insurance sets climate steps t...   \n",
       "..           ...                                                ...   \n",
       "95  The Guardian  Is deep-sea mining a cure for the climate cris...   \n",
       "96     Zacks.com  Auto Stock Roundup: AAP & XPEV's Q2 Results, F...   \n",
       "97       Reuters  Illinois Senate passes bill to save nuclear pl...   \n",
       "98       Reuters  Illinois Senate passes bill to save nuclear pl...   \n",
       "99       Reuters  UPDATE 1-Illinois Senate passes bill to save n...   \n",
       "\n",
       "                                          description  \\\n",
       "0   Although wireless charging is still relatively...   \n",
       "1   Hyundai Motor Group is backing hydrogen as a t...   \n",
       "2   Electric vehicles (EVs) coupled with low-carbo...   \n",
       "3   Zurich Insurance Group <a href=\"https://www.re...   \n",
       "4   Zurich Insurance Group unveiled new climate me...   \n",
       "..                                                ...   \n",
       "95  Trillions of metallic nodules on the sea floor...   \n",
       "96  While Advance Auto Parts (AAP) and XPeng (XPEV...   \n",
       "97  The Illinois Senate passed a bill early on Wed...   \n",
       "98  The Illinois Senate passed a bill early on Wed...   \n",
       "99  The Illinois Senate passed a bill early on Wed...   \n",
       "\n",
       "                                              content  \n",
       "0   President Joe Biden’s plan for electric vehicl...  \n",
       "1   Hyundai Motor Group is backing hydrogen as a t...  \n",
       "2   Introduction\\r\\nOur global society is dependen...  \n",
       "3   CEO Mario Greco of Swiss Zurich Insurance addr...  \n",
       "4   By Reuters Staff\\r\\nFILE PHOTO: CEO Mario Grec...  \n",
       "..                                                ...  \n",
       "95  In a display cabinet in the recently opened Ou...  \n",
       "96  August\\r\\n30, 2021\\r\\n5 min read\\r\\nThis story...  \n",
       "97  The company and law firm names shown above are...  \n",
       "98  (Reuters) - The Illinois Senate passed a bill ...  \n",
       "99  (Adds Exelon comment)\\r\\nSept 1 (Reuters) - Th...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it turns out that all these articles were published in 2021, so this feature is no longer useful. \n",
    "DF = DF.drop(labels = ['publishedAt'], axis = 1)\n",
    "\n",
    "# here is what the dataset looks like now:\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning\n",
    "\n",
    "The only acceptable column is _source_ at the moment. For the features _title, description, content_, it is necessary to do the following data cleaning:\n",
    "\n",
    "1. convert all text to lower case for consistency\n",
    "2. remove parenthesized contents, e.g. (EVs), (Reuters), (Adds Exelon comment)\n",
    "    - [Stackoverflow regex solution](https://stackoverflow.com/questions/640001/how-can-i-remove-text-within-parentheses-with-a-regex)\n",
    "3. remove all link references\n",
    "4. remove all punctuation\n",
    "5. remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk # nlp module\n",
    "from nltk.corpus import stopwords # for stopwords later\n",
    "import string # to call string methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ercongluo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "punc = string.punctuation # string of punctuation characters\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\")) # for removing stop words \n",
    "\n",
    "for j in ['title', 'description', 'content']: # iterated over these labels\n",
    "    for i in range(0,100): # iterated over all 100 collected articles\n",
    "        # 1. convert all text to lower case for consistency\n",
    "        DF[j][i] = DF[j][i].lower()\n",
    "        \n",
    "        # 2. remove parenthesized contents\n",
    "        # parenthesized contents are represented in re package\n",
    "        # as \\([^)]*\\), see reference\n",
    "        re.sub(r'\\([^)]*\\)', '', DF[j][i])\n",
    "               \n",
    "        # 3. remove all link references\n",
    "        re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"\", DF[j][i])\n",
    "        \n",
    "        # 4. replace all punctuation with an empty space\n",
    "        for char in DF[j][i]:\n",
    "            if char in punc:\n",
    "                DF[j][i] = DF[j][i].replace(char, \" \")\n",
    "        \n",
    "        # 5. remove stop words\n",
    "        # reference for the line of code below: (I did take the time to understand this one-liner)\n",
    "        # https://towardsdatascience.com/a-guide-to-cleaning-text-in-python-943356ac86ca\n",
    "        DF[j][i] = \" \".join([word for word in DF[j][i].split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>ev charging solutions become asset liability grid</td>\n",
       "      <td>although wireless charging still relatively ne...</td>\n",
       "      <td>president joe biden’s plan electric vehicles e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>hyundai motor group unveils hydrogen strategy ...</td>\n",
       "      <td>hyundai motor group backing hydrogen top energ...</td>\n",
       "      <td>hyundai motor group backing hydrogen top energ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wiley.com</td>\n",
       "      <td>electric vehicles produce substantial toxicity...</td>\n",
       "      <td>electric vehicles evs coupled low carbon elect...</td>\n",
       "      <td>introduction global society dependent road tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>zurich insurance sets climate steps curb c02 e...</td>\n",
       "      <td>zurich insurance group href https www reuters ...</td>\n",
       "      <td>ceo mario greco swiss zurich insurance address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>update 1 zurich insurance sets climate steps c...</td>\n",
       "      <td>zurich insurance group unveiled new climate me...</td>\n",
       "      <td>reuters staff file photo ceo mario greco swiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Guardian</td>\n",
       "      <td>deep sea mining cure climate crisis curse</td>\n",
       "      <td>trillions metallic nodules sea floor could hel...</td>\n",
       "      <td>display cabinet recently opened broken planet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zacks.com</td>\n",
       "      <td>auto stock roundup aap xpev q2 results f outpu...</td>\n",
       "      <td>advance auto parts aap xpeng xpev deliver impr...</td>\n",
       "      <td>august 30 2021 5 min read story originally app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>illinois senate passes bill save nuclear plant...</td>\n",
       "      <td>illinois senate passed bill early wednesday ai...</td>\n",
       "      <td>company law firm names shown generated automat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>illinois senate passes bill save nuclear plant...</td>\n",
       "      <td>illinois senate passed bill early wednesday ai...</td>\n",
       "      <td>reuters illinois senate passed bill early wedn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>update 1 illinois senate passes bill save nucl...</td>\n",
       "      <td>illinois senate passed bill early wednesday ai...</td>\n",
       "      <td>adds exelon comment sept 1 reuters illinois se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source                                              title  \\\n",
       "0     TechCrunch  ev charging solutions become asset liability grid   \n",
       "1     TechCrunch  hyundai motor group unveils hydrogen strategy ...   \n",
       "2      Wiley.com  electric vehicles produce substantial toxicity...   \n",
       "3        Reuters  zurich insurance sets climate steps curb c02 e...   \n",
       "4        Reuters  update 1 zurich insurance sets climate steps c...   \n",
       "..           ...                                                ...   \n",
       "95  The Guardian          deep sea mining cure climate crisis curse   \n",
       "96     Zacks.com  auto stock roundup aap xpev q2 results f outpu...   \n",
       "97       Reuters  illinois senate passes bill save nuclear plant...   \n",
       "98       Reuters  illinois senate passes bill save nuclear plant...   \n",
       "99       Reuters  update 1 illinois senate passes bill save nucl...   \n",
       "\n",
       "                                          description  \\\n",
       "0   although wireless charging still relatively ne...   \n",
       "1   hyundai motor group backing hydrogen top energ...   \n",
       "2   electric vehicles evs coupled low carbon elect...   \n",
       "3   zurich insurance group href https www reuters ...   \n",
       "4   zurich insurance group unveiled new climate me...   \n",
       "..                                                ...   \n",
       "95  trillions metallic nodules sea floor could hel...   \n",
       "96  advance auto parts aap xpeng xpev deliver impr...   \n",
       "97  illinois senate passed bill early wednesday ai...   \n",
       "98  illinois senate passed bill early wednesday ai...   \n",
       "99  illinois senate passed bill early wednesday ai...   \n",
       "\n",
       "                                              content  \n",
       "0   president joe biden’s plan electric vehicles e...  \n",
       "1   hyundai motor group backing hydrogen top energ...  \n",
       "2   introduction global society dependent road tra...  \n",
       "3   ceo mario greco swiss zurich insurance address...  \n",
       "4   reuters staff file photo ceo mario greco swiss...  \n",
       "..                                                ...  \n",
       "95  display cabinet recently opened broken planet ...  \n",
       "96  august 30 2021 5 min read story originally app...  \n",
       "97  company law firm names shown generated automat...  \n",
       "98  reuters illinois senate passed bill early wedn...  \n",
       "99  adds exelon comment sept 1 reuters illinois se...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF # see what the dataframe looks like now. looking good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataframe now is already pretty good data, so it will be saved as is for later use as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('NewsData_cleanedDF.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Article Contents into bag-of-word (BOW) Representations using CountVectorizer()\n",
    "\n",
    "Key function: \n",
    "\n",
    "> sklearn.feature_extraction.text.CountVectorizer()\n",
    "\n",
    "Documentation: [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = DF['content'].tolist() # convert the contents into a list of strings, each string is an article\n",
    "\n",
    "# it is discovered that there are too many numeric characters in the dataset and they are of no use for now\n",
    "# so the following chunk of code takes them out using regex\n",
    "for article in corpus:\n",
    "    article = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", article)\n",
    "\n",
    "    \n",
    "stop_words = stop_words.union({'107', # tried regex to eliminate numeric characters but failed \n",
    "                             '10950', # so here's a brute-force solution\n",
    "                             '12',\n",
    "                             '1305',\n",
    "                             '13052',\n",
    "                             '1363',\n",
    "                             '13th',\n",
    "                             '1424',\n",
    "                             '1472',\n",
    "                             '1480',\n",
    "                             '14932',\n",
    "                             '1526',\n",
    "                             '15961',\n",
    "                             '16017',\n",
    "                             '1655',\n",
    "                             '1671',\n",
    "                             '16th',\n",
    "                             '17',\n",
    "                             '1745',\n",
    "                             '179',\n",
    "                             '1816',\n",
    "                             '1837',\n",
    "                             '1846',\n",
    "                             '1885',\n",
    "                             '1888',\n",
    "                             '1957',\n",
    "                             '196',\n",
    "                             '1970',\n",
    "                             '1973',\n",
    "                             '1988',\n",
    "                             '20',\n",
    "                             '2015',\n",
    "                             '2016',\n",
    "                             '2019',\n",
    "                             '2023',\n",
    "                             '2050',\n",
    "                             '2078',\n",
    "                             '2105',\n",
    "                             '21202',\n",
    "                             '2179',\n",
    "                             '2201',\n",
    "                             '2220',\n",
    "                             '2294',\n",
    "                             '2303',\n",
    "                             '2310',\n",
    "                             '2383',\n",
    "                             '24',\n",
    "                             '2416',\n",
    "                             '2465',\n",
    "                             '25',\n",
    "                             '2500',\n",
    "                             '2507',\n",
    "                             '2633',\n",
    "                             '2736',\n",
    "                             '2787',\n",
    "                             '28',\n",
    "                             '2840',\n",
    "                             '2844',\n",
    "                             '2873',\n",
    "                             '2894',\n",
    "                             '29',\n",
    "                             '300',\n",
    "                             '3069',\n",
    "                             '3108',\n",
    "                             '3130',\n",
    "                             '3164',\n",
    "                             '3179',\n",
    "                             '3277',\n",
    "                             '3278',\n",
    "                             '333',\n",
    "                             '3500',\n",
    "                             '3567',\n",
    "                             '3653',\n",
    "                             '3701',\n",
    "                             '3821',\n",
    "                             '3879',\n",
    "                             '4047',\n",
    "                             '4084',\n",
    "                             '4247',\n",
    "                             '43',\n",
    "                             '4423',\n",
    "                             '4534',\n",
    "                             '4568',\n",
    "                             '45710',\n",
    "                             '4589',\n",
    "                             '4762',\n",
    "                             '4837',\n",
    "                             '4940',\n",
    "                             '4954',\n",
    "                             '50',\n",
    "                             '500',\n",
    "                             '5075',\n",
    "                             '5210',\n",
    "                             '5301',\n",
    "                             '5574',\n",
    "                             '5633',\n",
    "                             '5637',\n",
    "                             '5682',\n",
    "                             '5722',\n",
    "                             '5889',\n",
    "                             '5932',\n",
    "                             '5974',\n",
    "                             '5996',\n",
    "                             '6052',\n",
    "                             '6128',\n",
    "                             '66',\n",
    "                             '6694',\n",
    "                             '6784',\n",
    "                             '6827',\n",
    "                             '70',\n",
    "                             '72',\n",
    "                             '7402',\n",
    "                             '7459',\n",
    "                             '7517',\n",
    "                             '8288',\n",
    "                             '83',\n",
    "                             '8309',\n",
    "                             '8399',\n",
    "                             '8466',\n",
    "                             '852',\n",
    "                             '882',\n",
    "                             '8883',\n",
    "                             '8901'})\n",
    "MyCV = CountVectorizer(input = corpus, encoding='utf-8', decode_error = 'ignore',\n",
    "                      stop_words = stop_words\n",
    "                       #, max_features = 200\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MyCV.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = MyCV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_DF = pd.DataFrame(X.toarray(), columns = colNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Write the result to .csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_DF.to_csv(\"newsData_BOW.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
