{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/ercongluo/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### setup ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re # data cleaning\n",
    "import emoji # data cleaning\n",
    "import nltk # data cleaning\n",
    "import string # data cleaning\n",
    "from sklearn.feature_extraction.text import CountVectorizer # data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4935, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19914257</td>\n",
       "      <td>Joe Biden's entire life has been crafted, in m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1140736721753182208</td>\n",
       "      <td>Aint she the one that was washing cars and giv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She/Her</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>831285669477699584</td>\n",
       "      <td>@RepAshleyHinson @RepAngieCraig @RodneyDavis @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maryland, USA</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14252968</td>\n",
       "      <td>@BunRab @UrsulaV @ldpm I remember the I-35 upp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16306558</td>\n",
       "      <td>@fadeaccompli @UrsulaV @ldpm You remember at a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baltimore, Maryland, USA</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1405643130</td>\n",
       "      <td>#German #climate policy in the making:\\n\\n- #c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Helsinki, Finland</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>218307802</td>\n",
       "      <td>@TomStDenis2 @StephenBlais @fordnation @OntLib...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ottawa, Ontario</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3788455876</td>\n",
       "      <td>You Might Be Creepy Cases Of Cars Into Ice Cre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1385288779712323595</td>\n",
       "      <td>@Milnoc @StephenBlais @fordnation @OntLiberal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1385288779712323595</td>\n",
       "      <td>Or is it because many ICE vehicles are still b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                                               text  \\\n",
       "0             19914257  Joe Biden's entire life has been crafted, in m...   \n",
       "1  1140736721753182208  Aint she the one that was washing cars and giv...   \n",
       "2   831285669477699584  @RepAshleyHinson @RepAngieCraig @RodneyDavis @...   \n",
       "3             14252968  @BunRab @UrsulaV @ldpm I remember the I-35 upp...   \n",
       "4             16306558  @fadeaccompli @UrsulaV @ldpm You remember at a...   \n",
       "5           1405643130  #German #climate policy in the making:\\n\\n- #c...   \n",
       "6            218307802  @TomStDenis2 @StephenBlais @fordnation @OntLib...   \n",
       "7           3788455876  You Might Be Creepy Cases Of Cars Into Ice Cre...   \n",
       "8  1385288779712323595  @Milnoc @StephenBlais @fordnation @OntLiberal ...   \n",
       "9  1385288779712323595  Or is it because many ICE vehicles are still b...   \n",
       "\n",
       "  country                  location label  \n",
       "0     NaN             Arlington, VA   ICE  \n",
       "1     NaN                   She/Her   ICE  \n",
       "2     NaN             Maryland, USA   ICE  \n",
       "3     NaN                       NaN   ICE  \n",
       "4     NaN  Baltimore, Maryland, USA   ICE  \n",
       "5     NaN         Helsinki, Finland   ICE  \n",
       "6     NaN           Ottawa, Ontario   ICE  \n",
       "7     NaN                       NaN   ICE  \n",
       "8     NaN                       NaN   ICE  \n",
       "9     NaN                       NaN   ICE  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"twitter_binary_classification.csv\")\n",
    "df.drop_duplicates()\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe Biden's entire life has been crafted, in m...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aint she the one that was washing cars and giv...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@RepAshleyHinson @RepAngieCraig @RodneyDavis @...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BunRab @UrsulaV @ldpm I remember the I-35 upp...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@fadeaccompli @UrsulaV @ldpm You remember at a...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#German #climate policy in the making:\\n\\n- #c...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@TomStDenis2 @StephenBlais @fordnation @OntLib...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>You Might Be Creepy Cases Of Cars Into Ice Cre...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@Milnoc @StephenBlais @fordnation @OntLiberal ...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Or is it because many ICE vehicles are still b...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Joe Biden's entire life has been crafted, in m...   ICE\n",
       "1  Aint she the one that was washing cars and giv...   ICE\n",
       "2  @RepAshleyHinson @RepAngieCraig @RodneyDavis @...   ICE\n",
       "3  @BunRab @UrsulaV @ldpm I remember the I-35 upp...   ICE\n",
       "4  @fadeaccompli @UrsulaV @ldpm You remember at a...   ICE\n",
       "5  #German #climate policy in the making:\\n\\n- #c...   ICE\n",
       "6  @TomStDenis2 @StephenBlais @fordnation @OntLib...   ICE\n",
       "7  You Might Be Creepy Cases Of Cars Into Ice Cre...   ICE\n",
       "8  @Milnoc @StephenBlais @fordnation @OntLiberal ...   ICE\n",
       "9  Or is it because many ICE vehicles are still b...   ICE"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text', 'label']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some data cleaning for each tweet: \n",
    "def cleaner(tweet):\n",
    "    tweet = tweet.lower() # to lower case\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    \n",
    "    # documentation for the following chunks of code: https://stackoverflow.com/questions/64719706/cleaning-twitter-data-pandas-python\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "    return tweet\n",
    "for i in range(df.shape[0]):\n",
    "    df.text[i] = cleaner(df.text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joe entire life been in many ways around — the...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aint she the one that was washing and giving a...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>by any necessary protect our precious from des...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i remember the i35 upper deck traffic camera f...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you remember at all where we lived in travis a...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>german climate policy in the making coal by 20...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tomstdenis2 with the exception of ice do not c...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>you might be creepy of into ice cream get style</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>your right ice catch fire so often that it doe...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>or is it because many ice are still bog stupid...</td>\n",
       "      <td>ICE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  joe entire life been in many ways around — the...   ICE\n",
       "1  aint she the one that was washing and giving a...   ICE\n",
       "2  by any necessary protect our precious from des...   ICE\n",
       "3  i remember the i35 upper deck traffic camera f...   ICE\n",
       "4  you remember at all where we lived in travis a...   ICE\n",
       "5  german climate policy in the making coal by 20...   ICE\n",
       "6  tomstdenis2 with the exception of ice do not c...   ICE\n",
       "7    you might be creepy of into ice cream get style   ICE\n",
       "8  your right ice catch fire so often that it doe...   ICE\n",
       "9  or is it because many ice are still bog stupid...   ICE"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and training sets: \n",
    "vectorizer = CountVectorizer(stop_words = \"english\")\n",
    "X = vectorizer.fit_transform(df.text)\n",
    "Y = df.label\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train NB, multinomial is the best model in this case\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB(alpha = 1, \n",
    "                   fit_prior = True)\n",
    "#Train model\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[550,  39],\n",
       "       [ 32, 366]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92806484295846"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
